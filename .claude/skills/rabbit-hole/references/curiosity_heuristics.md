# Curiosity Heuristics (흥미도 판단)

**목표:** 새로 발견한 개념의 興미(흥미)를 판단하여 큐에 추가할지 결정

**원칙:** 룰베이스 아님! LLM 직관 + 가이드라인

---

## 興미 점수 산정

### 4가지 요소

#### 1. 근본성 (Fundamentality) - 가중치 30%

**더 근본적일수록 흥미로움**

```
높음 (+0.3):
- 원리, 기초 이론
- "왜?"에 대한 답
- 다른 개념의 기반

예: "Majorana" ← Majorana가 뭔데? (근본)

중간 (+0.2):
- 메커니즘, 프로세스
- "어떻게?"에 대한 답

예: "Kitaev chain" ← 어떻게 모델링?

낮음 (+0.1):
- 응용, 구현
- "어디에?"에 대한 답

예: "Microsoft qubit" ← 어디에 쓰나?
```

#### 2. 연결성 (Connectivity) - 가중치 30%

**원래 질문/구멍과 연결될수록 흥미로움**

```
높음 (+0.3):
- 원래 질문과 직결
- "실용화 시기" 질문 → "Microsoft 타임라인" 발견

중간 (+0.2):
- 부모 구멍과 연관
- "Majorana" 파다가 → "Kitaev chain" 발견

낮음 (+0.1):
- 간접적 연관
- "양자 컴퓨팅" → "양자 화학" (다른 분야)
```

#### 3. 신선도 (Novelty) - 가중치 25%

**완전히 새로울수록 흥미로움**

```
높음 (+0.3):
- 완전 새로운 개념
- 처음 듣는 용어
- 예상 못 했던 발견

예: "Majorana 페르미온" (처음 들어봄!)

중간 (+0.2):
- 들어본 적 있지만 몰랐음
- 예상했지만 확인 필요

예: "표면 코드" (들어봤는데 뭔지는 몰라)

낮음 (+0.1):
- 이미 아는 개념
- 예상했던 것

예: "오류율" (당연히 중요하지)
```

#### 4. 구체성 (Concreteness) - 가중치 15%

**구체적일수록 검증/탐구 가능**

```
높음 (+0.3):
- 구체적 사례, 실험
- 숫자, 데이터
- 구현 가능

예: "IBM 0.1% 오류율 달성"

중간 (+0.2):
- 방법론, 프로세스
- 이론적이지만 명확

예: "표면 코드 알고리즘"

낮음 (+0.1):
- 추상적 개념
- 정의 애매

예: "양자 우위" (뭐가 우위?)
```

---

## 興미 점수 계산

### 공식

```
興미 = 근본성 * 0.3 + 연결성 * 0.3 + 신선도 * 0.25 + 구체성 * 0.15
```

**범위:** 0.0 ~ 1.0

### 임계값

```
興미 > 0.70 → 큐 추가 ✓
興미 < 0.70 → 무시
```

---

## 예시

### 예시 1: "Majorana 페르미온"

**맥락:** "토폴로지 코드" 검색 중 발견

```
근본성: +0.3 (토폴로지의 기초 입자)
연결성: +0.2 (부모 구멍과 연관)
신선도: +0.3 (완전 새로운 개념!)
구체성: +0.1 (이론적)

興미 = 0.3*0.3 + 0.2*0.3 + 0.3*0.25 + 0.1*0.15
     = 0.09 + 0.06 + 0.075 + 0.015
     = 0.24... 잠깐, 이건 너무 낮은데?
```

**재계산 (절대값):**

```
근본성: 0.9 (매우 근본적)
연결성: 0.7 (부모와 연관)
신선도: 1.0 (완전 새로움)
구체성: 0.5 (이론적)

興미 = 0.9*0.3 + 0.7*0.3 + 1.0*0.25 + 0.5*0.15
     = 0.27 + 0.21 + 0.25 + 0.075
     = 0.805

→ 0.805 > 0.70 ✓ 큐 추가!
```

### 예시 2: "Microsoft topological qubit"

**맥락:** "Majorana" 검색 중 발견

```
근본성: 0.4 (응용 단계)
연결성: 1.0 (원래 질문 "실용화"와 직결!)
신선도: 0.6 (알려진 주제)
구체성: 0.9 (구체적 구현)

興미 = 0.4*0.3 + 1.0*0.3 + 0.6*0.25 + 0.9*0.15
     = 0.12 + 0.30 + 0.15 + 0.135
     = 0.705

→ 0.705 > 0.70 ✓ 큐 추가!
```

### 예시 3: "양자 화학"

**맥락:** "양자 컴퓨팅" 검색 중 발견

```
근본성: 0.5 (관련 분야)
연결성: 0.3 (간접적)
신선도: 0.4 (들어봤음)
구체성: 0.5 (추상적)

興미 = 0.5*0.3 + 0.3*0.3 + 0.4*0.25 + 0.5*0.15
     = 0.15 + 0.09 + 0.10 + 0.075
     = 0.415

→ 0.415 < 0.70 ❌ 무시
```

---

## LLM 판단 (자연스럽게)

**공식만 따르지 마세요!**

Extended Thinking으로 종합 판단:

```markdown
발견: "Kitaev chain model"

계산:
- 근본성: 0.8
- 연결성: 0.7
- 신선도: 0.9
- 구체성: 0.6
→ 興미: 0.765

하지만...
직관적으로:
- "Kitaev가 Majorana의 기초 모델이네"
- "이론적이라 실용화랑은 좀 거리가..."
- "나중에 파도 될 것 같은데"

최종 판단:
→ 興미: 0.75 (약간 낮춤)
→ 큐 추가하되 우선순위 낮음
```

**기계적 계산 + LLM 직관 = 최종 판단**

---

## 특수 상황

### 모순 발견

```
기존: "표면 코드가 최선"
새 발견: "토폴로지가 더 낫다"

→ 모순!
→ 興미 자동 +0.2 (모순 해소 중요)
```

### 원래 질문과 직결

```
원래 질문: "실용화 시기?"
발견: "2030년 타임라인"

→ 直結!
→ 興미 자동 +0.3
```

### 빈도 높음

```
검색 결과 10개 중 8개에서 언급
→ "중요한가 보네"
→ 興미 +0.1
```

---

## 자주 하는 실수

### ❌ 잘못된 예

1. **기계적 계산만**
   ```
   興미 = 0.71 → 큐 추가
   (직관: 별로 안 끌리는데...)
   → 계산만 믿지 말 것!
   ```

2. **너무 많이 추가**
   ```
   모든 발견 → 큐 추가
   → 큐가 100개...
   → 임계값 0.70 지키기!
   ```

3. **원래 질문 무시**
   ```
   "실용화 시기" 질문인데
   "양자역학 철학" 발견 → 興미 0.9
   → 연결성 낮음! 무시해야
   ```

### ✅ 올바른 예

1. **직관 + 계산**
   ```
   計算: 0.75
   直觀: "이게 더 중요한 것 같은데"
   → 最終: 0.85
   ```

2. **선택과 집중**
   ```
   발견 10개 중 興미 높은 3개만 큐 추가
   → 큐 크기 관리
   ```

3. **원래 질문 기준**
   ```
   "실용화 시기" 질문
   → "타임라인", "로드맵" 관련 발견에 높은 興미
   ```

---

## 코드 예시

```python
def judge_curiosity(discovery, context):
    """
    Extended Thinking으로 흥미도 판단
    """

    # 1. 기본 점수 계산
    fundamentality = assess_fundamentality(discovery)
    connectivity = assess_connectivity(discovery, context)
    novelty = assess_novelty(discovery, context.known_concepts)
    concreteness = assess_concreteness(discovery)

    base_score = (
        fundamentality * 0.3 +
        connectivity * 0.3 +
        novelty * 0.25 +
        concreteness * 0.15
    )

    # 2. 특수 상황 보정
    if is_contradiction(discovery, context.current_beliefs):
        base_score += 0.2

    if directly_answers_question(discovery, context.original_question):
        base_score += 0.3

    # 3. LLM 직관 (Extended Thinking)
    intuition_adjustment = llm_intuition(
        discovery=discovery,
        base_score=base_score,
        context=context
    )

    # 4. 최종 점수
    final_score = min(1.0, base_score + intuition_adjustment)

    return {
        "interest": final_score,
        "should_add": final_score > 0.70,
        "reasoning": llm_reasoning
    }
```

---

**興미를 따라가세요! 흥미로운 것이 진리로 이끕니다.** 🐰✨
