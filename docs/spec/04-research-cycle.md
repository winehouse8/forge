# ì—°êµ¬ ì‚¬ì´í´ (9ë‹¨ê³„) + Memory Blocks

**ë¬¸ì„œ:** 04-research-cycle.md
**ìµœì¢… ìˆ˜ì •ì¼:** 2026-02-01 (v5 - Memory Blocks Enhanced)
**ìˆ˜ì •ì:** Claude Sonnet 4.5
**ê´€ë ¨ íŒŒì¼:** `.claude/skills/deep-research/SKILL.md`, `config.json:16-36`, `.research/memory_manager.py`

---

## ëª©ì°¨
- [ì‚¬ì´í´ ê°œìš”](#ì‚¬ì´í´-ê°œìš”)
- [ê° ë‹¨ê³„ ìƒì„¸](#ê°-ë‹¨ê³„-ìƒì„¸)
- [ë³‘ë ¬ ì²˜ë¦¬ ì „ëµ](#ë³‘ë ¬-ì²˜ë¦¬-ì „ëµ)
- [ì‚¬ê³  ë„êµ¬](#ì‚¬ê³ -ë„êµ¬)
- [Loop Drift ë°©ì§€](#loop-drift-ë°©ì§€)

---

## ì‚¬ì´í´ ê°œìš”

### 9ë‹¨ê³„ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. LOAD      - ìƒíƒœ íŒŒì¼ ì½ê¸°                           â”‚
â”‚       â†“                                                  â”‚
â”‚  2. REFLECT   - Extended Thinkingìœ¼ë¡œ ê¹Šì´ ë¶„ì„         â”‚
â”‚       â†“                                                  â”‚
â”‚  3. PLAN      - 2-Phase ì „ëµ (10+ í›„ë³´ â†’ 3-5ê°œ ì„ íƒ)    â”‚
â”‚       â†“                                                  â”‚
â”‚  4. EXECUTE   - ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰ (WebSearch/Fetch)         â”‚
â”‚       â†“                                                  â”‚
â”‚  5. VERIFY    - 4ê³„ì¸µ ê²€ì¦ ì‹œìŠ¤í…œ ì ìš©                   â”‚
â”‚       â†“                                                  â”‚
â”‚  6. SYNTHESIZE - ì§€ì‹ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸, ê°€ì„¤ í‰ê°€         â”‚
â”‚       â†“                                                  â”‚
â”‚  7. SAVE      - ëª¨ë“  ìƒíƒœ íŒŒì¼ ì €ì¥                      â”‚
â”‚       â†“                                                  â”‚
â”‚  8. OUTPUT    - ì§„í–‰ ìƒí™© ì¶œë ¥                           â”‚
â”‚       â†“                                                  â”‚
â”‚  9. LOOP      - ì¢…ë£Œ ì¡°ê±´ ì²´í¬ â†’ Skill ì¬í˜¸ì¶œ            â”‚
â”‚       â”‚                                                  â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ë‹¨ê³„ë³„ ì†Œìš” ì‹œê°„ (ì˜ˆìƒ)

| ë‹¨ê³„ | ì†Œìš” ì‹œê°„ | ì£¼ìš” ì‘ì—… |
|------|----------|----------|
| 1. LOAD | 5ì´ˆ | íŒŒì¼ ì½ê¸° (4ê°œ) |
| 2. REFLECT | 30ì´ˆ | Extended Thinking |
| 3. PLAN | 10ì´ˆ | ì¿¼ë¦¬ ìƒì„± |
| 4. EXECUTE | 60ì´ˆ | ë³‘ë ¬ ê²€ìƒ‰ (3-5ê°œ) |
| 5. VERIFY | 20ì´ˆ | êµì°¨ ê²€ì¦ |
| 6. SYNTHESIZE | 30ì´ˆ | ì§€ì‹ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ |
| 7. SAVE | 10ì´ˆ | íŒŒì¼ ì“°ê¸° (6ê°œ) |
| 8. OUTPUT | 5ì´ˆ | ì¶œë ¥ ìƒì„± |
| 9. LOOP | 5ì´ˆ | ì¢…ë£Œ ì¡°ê±´ ì²´í¬ |
| **ì´** | **2-3ë¶„** | **1 iteration** |

---

## ê° ë‹¨ê³„ ìƒì„¸

### 0. í”„ë¡¬í”„íŠ¸ ì´ˆê¸° ì‹¤í–‰ (SKILL.md ì‹œì‘ ì‹œ)

**ëª©ì :** ì‚¬ì´í´ ì‹œì‘ ì „ í˜„ì¬ ìƒíƒœ íŒŒì¼ì„ í”„ë¡¬í”„íŠ¸ì— ìë™ ë¡œë“œ

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md:12-18`

**ì‹¤í–‰ ëª…ë ¹ì–´:**

```markdown
## í˜„ì¬ ìƒíƒœ ë¡œë“œ

í˜„ì¬ ì—°êµ¬ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤:
!`cat .research/state.json 2>/dev/null || echo '{"iteration":{"current":0}}'`

ìµœê·¼ ê²€ìƒ‰ íˆìŠ¤í† ë¦¬:
!`cat .research/search_history.json 2>/dev/null || echo '{"queries":[]}'`
```

**ë™ì‘:**
- Skill í”„ë¡¬í”„íŠ¸ê°€ ì‹¤í–‰ë  ë•Œ ìë™ìœ¼ë¡œ bash ëª…ë ¹ì–´ ì‹¤í–‰
- `!` prefixë¡œ ì¸í•´ ì¦‰ì‹œ ì‹¤í–‰ë˜ì–´ ê²°ê³¼ê°€ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë¨
- íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ JSON ë°˜í™˜ (ì´ˆê¸°í™”)

**íš¨ê³¼:**
- Agentê°€ ì‚¬ì´í´ ì‹œì‘ ì „ì— í˜„ì¬ ìƒíƒœë¥¼ ì¦‰ì‹œ íŒŒì•…
- LOAD ë‹¨ê³„ì—ì„œ ë³„ë„ë¡œ ì½ì„ í•„ìš” ì—†ìŒ (ì´ë¯¸ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë¨)

---

### 1. LOAD - ìƒíƒœ ë¡œë“œ (Memory Blocks Architecture)

**ëª©ì :** 3-tier Memory êµ¬ì¡°ë¡œ íš¨ìœ¨ì  ì»¨í…ìŠ¤íŠ¸ ë³µì›

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md`, `.research/memory_manager.py`

**3-Tier Memory ë¡œë“œ:**

```python
from memory_manager import MemoryManager

mm = MemoryManager()

# Working Memory (HOT - ìµœê·¼ 10 iterationsë§Œ)
working = mm.get_working_memory()
recent_iterations = working["iterations"]  # Observation masking ì ìš©

# Semantic Memory (STRUCTURED - í•µì‹¬ ë°œê²¬ë§Œ)
truncated_findings = mm.truncate_findings_for_context(max_findings=30)

# Archival Memory (COLD - í•„ìš” ì‹œë§Œ ì ‘ê·¼)
# old_iter = mm.retrieve_from_archival(iteration=5)
```

**í•„ìˆ˜ ì½ê¸° íŒŒì¼:**

| Memory Tier | íŒŒì¼ | ìš©ë„ | í¬ê¸° ì œí•œ |
|-------------|------|------|----------|
| **Working** | `working_memory.json` | ìµœê·¼ 10 iterations | 10ê°œ ê³ ì • |
| **Semantic** | `findings.md` | í•µì‹¬ ë°œê²¬ (truncated) | 30ê°œ ìµœì‹  |
| **Archival** | `archival/iteration_NNN.json` | ì „ì²´ ë¡œê·¸ (í•„ìš” ì‹œ) | ë¬´ì œí•œ |
| - | `state.json` | ì „ì²´ ìƒíƒœ, ê°€ì„¤ | - |
| - | `search_history.json` | ê²€ìƒ‰ ì¤‘ë³µ ë°©ì§€ | - |

**Observation Masking íš¨ê³¼:**
- ì»¨í…ìŠ¤íŠ¸ í¬ê¸°: 67% ê°ì†Œ (JetBrains Research)
- Cost saving + problem-solving ability ìœ ì§€
- ì˜¤ë˜ëœ ë°ì´í„°ëŠ” archivalì— ìë™ ì €ì¥

**ì²« ì‹¤í–‰ ì‹œ ì²˜ë¦¬:**

```
1. ì§ˆë¬¸ ë¶„í•´ (Query Decomposition)
   - ë³µì¡í•œ ì§ˆë¬¸ â†’ 3-5ê°œ ì„œë¸Œì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´
   - ê° ì„œë¸Œì§ˆë¬¸ì— ìš°ì„ ìˆœìœ„ ë¶€ì—¬

2. state.json ì´ˆê¸°í™”
   {
     "status": "running",
     "question": {
       "original": "ì‚¬ìš©ì ì§ˆë¬¸",
       "sub_questions": ["ì§ˆë¬¸1", "ì§ˆë¬¸2", ...]
     },
     "iteration": {"current": 0, "max": 100},
     "active_hypotheses": [],
     "all_hypotheses": []
   }
```

---

### 2. REFLECT - ë¶„ì„ (Extended Thinking)

**ëª©ì :** í˜„ì¬ ìƒí™©ì„ ê¹Šì´ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í–‰ë™ ê²°ì •

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md:44-53`

**ë¶„ì„ í•­ëª©:**

```markdown
## í˜„ì¬ ì•Œê³  ìˆëŠ” ê²ƒ
- [ì§€ê¸ˆê¹Œì§€ ë°œê²¬í•œ ì‚¬ì‹¤ë“¤ ë‚˜ì—´]

## ì•„ì§ ëª¨ë¥´ëŠ” ê²ƒ
- [ë¯¸í•´ê²° ì§ˆë¬¸ë“¤]

## í˜„ì¬ ê°€ì„¤
- ê°€ì„¤ 1: [ë‚´ìš©] (í™•ì‹ ë„: 75%)
  - ì§€ì§€ ì¦ê±°: [ì¦ê±°ë“¤]
  - ë°˜ì¦ ì¦ê±°: [ì¦ê±°ë“¤]

## ë§‰íŒ ë¶€ë¶„
- ë¬¸ì œ: [ì„¤ëª…]
- ì›ì¸: [ë¶„ì„]
- í•´ê²° ë°©ì•ˆ: [ëŒ€ì•ˆë“¤]

## í•„ìš”í•œ ì‚¬ê³  ë„êµ¬
- [ì œ1ì›ì¹™ / ì˜¤ì»´ì˜ ë©´ë„ë‚  / ë°˜ì¦ ê°€ëŠ¥ì„± ì¤‘ ì„ íƒ]
```

**Extended Thinking í™œìš©:**

- ëª¨ë“  ë¶„ì„ì€ `<thinking>` ë¸”ë¡ ë‚´ì—ì„œ ìˆ˜í–‰
- ìµœì†Œ 10ë‹¨ê³„ ì´ìƒì˜ ì¶”ë¡  ê³¼ì •
- ê°€ì • ëª…ì‹œ, ëŒ€ì•ˆ ê³ ë ¤

---

### 3. PLAN - ê³„íš (2-Phase ì „ëµ)

**ëª©ì :** ì´ë²ˆ iterationì˜ êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md:54-173`

**ì„¤ì •:** `config.json:16-36`

**êµ¬ì¡°:** ë°œì‚°(Divergent) â†’ ìˆ˜ë ´(Convergent) â†’ ì¤‘ë³µì œê±°(Deduplication)

#### Phase 0: Active Hypotheses í™•ì¸

í˜„ì¬ ì§‘ì¤‘í•  ìƒìœ„ 5ê°œ ê°€ì„¤ í™•ì¸:

```python
active_hypothesis_ids = state.get("active_hypotheses", [])
all_hypotheses = state.get("all_hypotheses", [])

if all_hypotheses and active_hypothesis_ids:
    active_hypotheses = [h for h in all_hypotheses if h["id"] in active_hypothesis_ids]
    print(f"ğŸ¯ Current Focus: {len(active_hypotheses)} active hypotheses")
    for h in active_hypotheses[:3]:
        print(f"  - [{h['id']}] {h['statement'][:50]}... (Priority: {h['priority_score']:.2f})")
else:
    print("ğŸ¯ ì²« iteration: ì „ì²´ íƒìƒ‰ ëª¨ë“œ")
```

**ì•ˆì „ì„± ì²˜ë¦¬:**
- ì²« iteration: `all_hypotheses` ì—†ìŒ â†’ ì „ì²´ íƒìƒ‰ ëª¨ë“œ
- ì´í›„ iteration: active_hypotheses ê¸°ë°˜ ì§‘ì¤‘ íƒìƒ‰

#### Phase 1: Divergent Thinking (ë°œì‚°)

**ëª©í‘œ:** 10ê°œ ì´ìƒ ì¿¼ë¦¬ í›„ë³´ ìƒì„±

**ê·œì¹™:**
- íŒë‹¨ ë³´ë¥˜ (no premature filtering)
- ë¸Œë ˆì¸ìŠ¤í† ë° ëª¨ë“œ
- ë‹¤ì–‘ì„± ìš°ì„ 

**ìƒì„± ì „ëµ:**

```markdown
## ì¼ë°˜ ì›¹ ê²€ìƒ‰ (3-4ê°œ)
- "keyword A B C 2026"
- "keyword D E F latest"

## í•™ìˆ /ê¸°ìˆ  ê²€ìƒ‰ (3-4ê°œ)
- "site:arxiv.org [topic]"
- "site:github.com [implementation]"

## ë°˜ì¦ ì¦ê±° íƒìƒ‰ (3-4ê°œ)
- "[hypothesis] criticism"
- "[hypothesis] counterexample"
- "[hypothesis] limitations fails when"

ê²°ê³¼: candidate_queries = [q1, ..., q10+]
```

#### Phase 2: Convergent Thinking (ìˆ˜ë ´)

**ëª©í‘œ:** ìƒìœ„ 3-5ê°œ ìµœì  ì¿¼ë¦¬ ì„ íƒ

**í‰ê°€ ê¸°ì¤€:**

| ê¸°ì¤€ | ì„¤ëª… | ê°€ì¤‘ì¹˜ |
|------|------|--------|
| ì •ë³´ ê°€ì¹˜ | ìƒˆë¡œìš´ ë°œê²¬ ê°€ëŠ¥ì„± | 40% |
| ë‹¤ì–‘ì„± | ë‹¤ë¥¸ ê°ë„/ì†ŒìŠ¤ | 30% |
| ì‹¤í–‰ ê°€ëŠ¥ì„± | êµ¬ì²´ì ì´ê³  ê²€ìƒ‰ ê°€ëŠ¥ | 20% |
| ì¤‘ë³µë„ | ë‚´ë¶€ ì¤‘ë³µ ì œê±° | 10% |

**ì„ íƒ í”„ë¡œì„¸ìŠ¤:**

ê° í›„ë³´ë¥¼ í‰ê°€í•˜ì—¬ ìƒìœ„ 3-5ê°œ ì„ íƒ

```
ê²°ê³¼: filtered_queries_phase2 = [top_3_to_5]
```

#### Phase 3: ì¤‘ë³µ ê²€ìƒ‰ ì œê±° (Deduplication)

ê³¼ê±° ê²€ìƒ‰ê³¼ì˜ ì¤‘ë³µ ì œê±° (>0.95 ìœ ì‚¬ë„):

```python
from deduplicate_search import is_duplicate_query

for query in filtered_queries_phase2:
    if not is_duplicate_query(query):
        final_queries.append(query)
```

**ìµœì¢… ê²°ê³¼:** `final_queries` = 3-5ê°œ ì‹¤í–‰ ì¿¼ë¦¬

**ì „ëµ ì„ íƒ ê¸°ì¤€:**

| ìƒí™© | ì „ëµ | ì´ìœ  |
|------|------|------|
| ìµœì‹  ë™í–¥ í•„ìš” | Web | ì¼ë°˜ ê²€ìƒ‰ì—”ì§„ì´ ìµœì‹  ì •ë³´ ë³´ìœ  |
| í•™ìˆ ì  ê·¼ê±° í•„ìš” | Academic | arXiv, IEEE ë“± ì‹ ë¢°ë„ ë†’ìŒ |
| í™•ì‹ ë„ > 80% | Verification | ë°˜ì¦ ì¦ê±° ì ê·¹ íƒìƒ‰ í•„ìš” |
| ëª¨ìˆœ ë°œê²¬ | Verification | êµì°¨ ê²€ì¦ |

---

### 4. EXECUTE - ì‹¤í–‰

**ëª©ì :** ê³„íšëœ ê²€ìƒ‰ì„ **ë³‘ë ¬ë¡œ** ì‹¤í–‰í•˜ì—¬ ì‹œê°„ ë‹¨ì¶•

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md:174-207`

**ë³‘ë ¬ ê²€ìƒ‰ ì˜ˆì‹œ:**

```python
# final_queries (PLAN Phase 3ì—ì„œ ì¤‘ë³µ ì œê±°ëœ ì¿¼ë¦¬)ë¡œ ê²€ìƒ‰ ì‹¤í–‰
WebSearch("final_query_1")  # ë³‘ë ¬
WebSearch("final_query_2")  # ë³‘ë ¬
WebSearch("final_query_3")  # ë³‘ë ¬

# ê²€ìƒ‰ ì‹¤í–‰ í›„ historyì— ì¶”ê°€ (embedding ìë™ ì €ì¥)
for query, result in zip(final_queries, search_results):
    add_query_to_history(
        query_text=query,
        iteration=current_iteration,
        results_count=len(result.get('items', [])),
        success=True
    )
```

**ì‹¤í–‰ ì‹œê°„:**
- ìˆœì°¨ ì‹¤í–‰: 30ì´ˆ Ã— 3 = 90ì´ˆ
- ë³‘ë ¬ ì‹¤í–‰: max(30ì´ˆ, 30ì´ˆ, 30ì´ˆ) = 30ì´ˆ
- **ì ˆê°: 60ì´ˆ (67%)**

**WebFetch í™œìš©:**

```
ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìœ ë§í•œ URL ë°œê²¬ ì‹œ:
â†’ WebFetch("https://...", "Extract key findings")  â† ë³‘ë ¬
â†’ WebFetch("https://...", "Extract methodology")   â† ë³‘ë ¬
â†’ WebFetch("https://...", "Extract limitations")   â† ë³‘ë ¬
```

**í•™ìˆ  ë…¼ë¬¸ ì²˜ë¦¬:**

```bash
# 1. arXiv ê²€ìƒ‰
WebSearch("site:arxiv.org transformer architecture")

# 2. PDF URL ì¶”ì¶œ
https://arxiv.org/pdf/2103.xxxxx.pdf

# 3. ë‹¤ìš´ë¡œë“œ
Bash("curl -L -o .research/papers/transformer.pdf https://arxiv.org/pdf/2103.xxxxx.pdf")

# 4. ë¶„ì„
Read(".research/papers/transformer.pdf")
```

**ì„¤ì •:** `config.json:16-36`

```json
"search": {
  "parallel_count": 3,
  "max_retries": 2,
  "strategies": {
    "web": {"enabled": true, "fetch_full_content": true},
    "academic": {
      "enabled": true,
      "sources": ["arxiv", "semantic_scholar"],
      "auto_download_pdf": true,
      "max_papers_per_query": 3
    },
    "verification": {
      "enabled": true,
      "search_contradictions": true
    }
  }
}
```

---

### 5. VERIFY - ê²€ì¦

**ëª©ì :** Hallucination ë°©ì§€, ëª¨ë“  ì£¼ì¥ì— ê·¼ê±° í™•ë³´

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md:208-231`

**ìƒì„¸:** [05-verification.md](./05-verification.md) ì°¸ì¡°

**4ê³„ì¸µ ê²€ì¦:**

```
Layer 1: Source Grounding
         â†“
Layer 2: Cross-Validation (2-3ê°œ ì†ŒìŠ¤ êµì°¨ í™•ì¸)
         â†“
Layer 3: Self-Consistency (ë‹¤ë¥¸ ê°ë„ì—ì„œ ì¬ê²€í† )
         â†“
Layer 4: Confidence Tagging (âœ“âœ“ / âœ“ / ~ / ? / âš )
```

**ì˜ˆì‹œ:**

```markdown
## ë°œê²¬ ì‚¬í•­

âœ“âœ“ GPT-4ëŠ” 2023ë…„ 3ì›” 14ì¼ ì¶œì‹œë˜ì—ˆë‹¤
   ì†ŒìŠ¤: openai.com, techcrunch.com, theverge.com
   ì‹ ë¢°ë„: 0.95

âœ“ Transformer ì•„í‚¤í…ì²˜ëŠ” 2017ë…„ "Attention Is All You Need" ë…¼ë¬¸ì—ì„œ ì œì•ˆë˜ì—ˆë‹¤
   ì†ŒìŠ¤: arxiv.org/abs/1706.03762
   ì‹ ë¢°ë„: 0.98

~ ì–‘ì ì»´í“¨í„°ëŠ” 2030ë…„ê¹Œì§€ ì‹¤ìš©í™”ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤
   ì†ŒìŠ¤: forbes.com (ì „ë¬¸ê°€ ì˜ˆì¸¡)
   ì‹ ë¢°ë„: 0.60

? GPT-5ì˜ ì¶œì‹œ ì‹œê¸°ëŠ” ë¶ˆëª…í™•í•˜ë‹¤
   ì†ŒìŠ¤: ì—†ìŒ (ê³µì‹ ë°œí‘œ ì—†ìŒ)
   ì‹ ë¢°ë„: 0.30

âš  "GPT-4ëŠ” AGIë¥¼ ë‹¬ì„±í–ˆë‹¤"ëŠ” ì£¼ì¥ì€ ë…¼ë€ì´ ìˆë‹¤
   ì§€ì§€: wired.com (ì¼ë¶€ ì „ë¬¸ê°€)
   ë°˜ëŒ€: nature.com (ëŒ€ë‹¤ìˆ˜ ì „ë¬¸ê°€)
   ì‹ ë¢°ë„: ëª¨ìˆœ
```

---

### 6. SYNTHESIZE - ì¢…í•©

**ëª©ì :** ìƒˆë¡œìš´ ì •ë³´ë¥¼ ê¸°ì¡´ ì§€ì‹ê³¼ í†µí•©, ê°€ì„¤ í‰ê°€ ë° ìš°ì„ ìˆœìœ„ ê´€ë¦¬

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md:232-330`

**ì‘ì—… íë¦„:**

```
1. Knowledge Graph ì—…ë°ì´íŠ¸
         â†“
2. ê°€ì„¤ í‰ê°€ ë° Priority-based Filtering
         â†“
3. Active Hypotheses ì„ íƒ (Top 5)
         â†“
4. Reflexion ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
```

**1. Knowledge Graph ì—…ë°ì´íŠ¸**

**íŒŒì¼:** `.research/knowledge_graph.json`

```json
{
  "nodes": [
    {
      "id": "gpt4_001",
      "label": "GPT-4",
      "type": "model",
      "confidence": 0.98,
      "added_iteration": 1
    },
    {
      "id": "transformer_001",
      "label": "Transformer Architecture",
      "type": "architecture",
      "confidence": 0.98,
      "added_iteration": 2
    }
  ],
  "edges": [
    {
      "from": "gpt4_001",
      "to": "transformer_001",
      "relation": "based_on",
      "confidence": 0.95,
      "sources": ["openai.com", "arxiv.org/..."],
      "added_iteration": 2
    }
  ]
}
```

**ì—…ë°ì´íŠ¸ ê·œì¹™:**
- ìƒˆë¡œìš´ ê°œë… â†’ ë…¸ë“œ ì¶”ê°€
- ê°œë… ê°„ ê´€ê³„ â†’ ì—£ì§€ ì¶”ê°€
- ëª¨ìˆœ ë°œê²¬ â†’ í”Œë˜ê·¸ ì¶”ê°€ (`"contradicted": true`)

**2. ê°€ì„¤ í‰ê°€ ë° Priority-based Filtering**

**ëª©í‘œ:** ìƒìœ„ 5ê°œ ê°€ì„¤ì— ì§‘ì¤‘í•˜ì—¬ Cognitive Load ê°ì†Œ

**í”„ë¡œì„¸ìŠ¤:**

```python
for hypothesis in hypotheses:
    # 2.1 ì§€ì§€/ë°˜ì¦ ì¦ê±° ì—°ê²°
    for finding in new_findings:
        if finding.get("hypothesis_id") == hypothesis["id"]:
            if finding["confidence"] >= 0.7:
                hypothesis["supporting_evidence"].append(...)
            else:
                hypothesis["contradicting_evidence"].append(...)

    # 2.2 í™•ì‹ ë„ ì¬ê³„ì‚° (ë² ì´ì§€ì•ˆ ì—…ë°ì´íŠ¸)
    support_weight = len(supporting_evidence) * 0.1
    contra_weight = len(contradicting_evidence) * 0.15
    hypothesis["confidence"] = max(0.0, min(1.0,
        current_confidence + support_weight - contra_weight
    ))

    # 2.3 Priority Score ê³„ì‚°
    # ê³µì‹: Confidence(50%) + Evidence Density(30%) + Recency(20%)
    evidence_density = (support - contra*0.5) / 10  # 0~1
    recency = 1.0 if last_updated >= iter-2 else 0.5
    hypothesis["priority_score"] = (
        confidence * 0.5 +
        evidence_density * 0.3 +
        recency * 0.2
    )

# 3. Active Hypotheses í•„í„°ë§ (Top 5)
hypotheses.sort(key=lambda h: h["priority_score"], reverse=True)
active_hypotheses = hypotheses[:5]
inactive_hypotheses = hypotheses[5:]

state["active_hypotheses"] = [h["id"] for h in active_hypotheses]
state["all_hypotheses"] = hypotheses
```

**ìŠ¤í‚¤ë§ˆ ì˜ˆì‹œ:**

```json
{
  "id": "hyp_001",
  "statement": "ì–‘ì ì»´í“¨í„°ëŠ” ì•”í˜¸í™” ì•Œê³ ë¦¬ì¦˜ì„ ìœ„í˜‘í•  ê²ƒì´ë‹¤",
  "confidence": 0.85,
  "priority_score": 0.78,
  "supporting_evidence": [
    {"source": "nature.com", "summary": "Shor's algorithm ì¦ëª…", "confidence": 0.95}
  ],
  "contradicting_evidence": [
    {"source": "arxiv.org", "summary": "ì‹¤ìš©í™”ê¹Œì§€ 10ë…„ ì´ìƒ ì†Œìš”", "confidence": 0.80}
  ],
  "last_updated_iteration": 5
}
```

**í™•ì‹ ë„ ì—…ë°ì´íŠ¸ ê·œì¹™:**

- ì§€ì§€ ì¦ê±° 1ê°œ ì¶”ê°€: +10%
- ë°˜ì¦ ì¦ê±° 1ê°œ ì¶”ê°€: -15%
- ë²”ìœ„: 0.0 ~ 1.0

**3. Reflexion ë©”ëª¨ë¦¬**

**íŒŒì¼:** `.research/reflexion.json`

```json
{
  "iterations": [
    {
      "iteration": 2,
      "action": "WebSearch(\"quantum computing applications\")",
      "outcome": "success",
      "lesson": "ì¼ë°˜ ê²€ìƒ‰ë³´ë‹¤ í•™ìˆ  ê²€ìƒ‰ì´ ë” ì •í™•í•œ ì •ë³´ ì œê³µ",
      "adjustment": "ë‹¤ìŒë¶€í„° ê¸°ìˆ  ì£¼ì œëŠ” arxiv ìš°ì„  ê²€ìƒ‰"
    },
    {
      "iteration": 3,
      "action": "WebSearch(\"GPT-4 release date\")",
      "outcome": "failure",
      "reason": "ì´ë¯¸ ê²€ìƒ‰í•œ ì¿¼ë¦¬ ë°˜ë³µ",
      "lesson": "search_history.json í™•ì¸ í•„ìˆ˜",
      "adjustment": "ê²€ìƒ‰ ì „ íˆìŠ¤í† ë¦¬ ì²´í¬ ì¶”ê°€"
    }
  ]
}
```

---

### 7. SAVE - ì €ì¥ (Memory Blocks ìë™ ê´€ë¦¬)

**ëª©ì :** 3-tier Memory êµ¬ì¡°ë¡œ íš¨ìœ¨ì  ì €ì¥ ë° ìë™ archival

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md`, `.research/memory_manager.py`

**3-Tier Memory ìë™ ì—…ë°ì´íŠ¸:**

```python
from memory_manager import MemoryManager

mm = MemoryManager()

# Working Memory (HOT - ìë™ observation masking)
mm.update_working_memory(
    iteration=current_iteration,
    findings=new_findings,
    queries_executed=final_queries,
    active_hypotheses=state["active_hypotheses"],
    next_actions=state["next_actions"]
)
# ë™ì‘:
# - working_memory.jsonì— ì¶”ê°€
# - 10ê°œ ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ ê²ƒì€ archivalë¡œ ìë™ ì´ë™
# - ìµœê·¼ 10ê°œë§Œ ìœ ì§€

# Semantic Memory (STRUCTURED)
mm.update_semantic_memory(findings_md_content)

# Archival Memory (COLD - ìë™ ì €ì¥)
# 11ë²ˆì§¸ ì´ì „ iterationsëŠ” .research/archival/iteration_NNN.jsonì— ìë™ ì €ì¥
```

**ì €ì¥ íŒŒì¼ ëª©ë¡:**

| Memory Tier | íŒŒì¼ | ì—…ë°ì´íŠ¸ ë‚´ìš© | í¬ê¸° ì œí•œ | í•„ìˆ˜ ì—¬ë¶€ |
|-------------|------|--------------|----------|----------|
| **Working** | `working_memory.json` | ìµœê·¼ 10 iterations | 10ê°œ ê³ ì • | âœ… í•„ìˆ˜ |
| **Semantic** | `findings.md` | í•µì‹¬ ë°œê²¬ ì‚¬í•­ | 30ê°œ ì¶”ì²œ | âœ… í•„ìˆ˜ |
| **Archival** | `archival/iteration_NNN.json` | ì „ì²´ iteration ë¡œê·¸ | ë¬´ì œí•œ | âœ… ìë™ |
| - | `state.json` | iteration +1, active_hypotheses, metrics | - | âœ… í•„ìˆ˜ |
| - | `search_history.json` | ì‹¤í–‰ëœ ì¿¼ë¦¬ (ìë™) | - | âœ… í•„ìˆ˜ |
| - | `knowledge_graph.json` | ë…¸ë“œ/ì—£ì§€ ì—…ë°ì´íŠ¸ | - | âš ï¸ í™œì„±í™” ì‹œ |
| - | `reflexion.json` | ì‹¤íŒ¨ í•™ìŠµ ê¸°ë¡ | - | âš ï¸ í™œì„±í™” ì‹œ |

**Observation Masking íš¨ê³¼:**
- ì»¨í…ìŠ¤íŠ¸ í¬ê¸°: 67% ê°ì†Œ
- Cost saving + problem-solving ability ìœ ì§€
- ê³¼ê±° ë°ì´í„°ëŠ” archivalì—ì„œ ì–¸ì œë“  ë³µì› ê°€ëŠ¥

**state.json ì—…ë°ì´íŠ¸ ì˜ˆì‹œ:**

```json
{
  "status": "running",
  "iteration": {
    "current": 3,
    "max": 100
  },
  "active_hypotheses": ["hyp_001", "hyp_003", "hyp_002", "hyp_005", "hyp_007"],
  "all_hypotheses": [
    {
      "id": "hyp_001",
      "confidence": 0.85,
      "priority_score": 0.78,
      "last_updated_iteration": 3
    }
  ],
  "next_actions": [
    "í•™ìˆ  ë…¼ë¬¸ì—ì„œ ë°˜ì¦ ì¦ê±° íƒìƒ‰",
    "ì‹¤í—˜ ê²°ê³¼ êµì°¨ ê²€ì¦"
  ],
  "metrics": {
    "cost_estimate_usd": 0.45,
    "queries_executed": 9,
    "sources_found": 27,
    "verified_facts": 12
  }
}
```

**findings.md í˜•ì‹:**

```markdown
# Research Findings

## Iteration 3 (2026-01-31 14:32)

### í•µì‹¬ ë°œê²¬
- âœ“âœ“ GPT-4ëŠ” Transformer ì•„í‚¤í…ì²˜ ê¸°ë°˜ (openai.com, arxiv.org)
- âœ“ 175B íŒŒë¼ë¯¸í„° ì‚¬ìš© (techcrunch.com)
- ~ í•™ìŠµ ë¹„ìš© ì•½ $100M ì¶”ì • (forbes.com)

### ê°€ì„¤ ì—…ë°ì´íŠ¸
- hyp_001: í™•ì‹ ë„ 75% â†’ 85% (ì§€ì§€ ì¦ê±° 2ê°œ ì¶”ê°€)

### ë‹¤ìŒ ê³„íš
- ë°˜ì¦ ì¦ê±° íƒìƒ‰: "GPT-4 limitations"
```

---

### 8. OUTPUT - ì¶œë ¥

**ëª©ì :** ì‚¬ìš©ìì—ê²Œ ì§„í–‰ ìƒí™©ì„ ëª…í™•í•˜ê²Œ ì „ë‹¬

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md:354-383`

**ì¶œë ¥ í˜•ì‹:**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š Iteration #3 ì™„ë£Œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” ì´ë²ˆ ë°œê²¬:
   - âœ“âœ“ GPT-4ëŠ” Transformer ê¸°ë°˜ (openai.com, arxiv.org)
   - âœ“ 175B íŒŒë¼ë¯¸í„° ì‚¬ìš© (techcrunch.com)
   - ~ í•™ìŠµ ë¹„ìš© ì•½ $100M ì¶”ì • (forbes.com)

ğŸ¯ Active Hypotheses (Top 5):
   1. [hyp_001] GPT-4ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ë‹¤
      í™•ì‹ ë„: 85% | Priority: 0.78 | ì§€ì§€: 2ê°œ | ë°˜ì¦: 0ê°œ
   2. [hyp_003] TransformerëŠ” ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì— ì ìš© ê°€ëŠ¥
      í™•ì‹ ë„: 80% | Priority: 0.72 | ì§€ì§€: 3ê°œ | ë°˜ì¦: 1ê°œ
   ...

ğŸ“‹ Inactive: 3ê°œ ê°€ì„¤ (ìš°ì„ ìˆœìœ„ ë‚®ìŒ, ì¬í‰ê°€ ëŒ€ê¸°)

ğŸ“ˆ ë‹¤ìŒ ê³„íš: active_hypotheses ê¸°ë°˜ íƒìƒ‰ ì „ëµ

ğŸ“Š ì§„í–‰ë„: 60% (3/5 ì„œë¸Œì§ˆë¬¸ ë‹µë³€ë¨)
   ì˜ˆì‚°: $0.45 / $10.00
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**ì„¤ì •:** `config.json:81-86`

```json
"output": {
  "verbosity": "normal",
  "show_confidence": true,
  "inline_citations": true,
  "progress_dashboard": true
}
```

---

### 9. LOOP - ë‹¤ìŒ Iteration ìë™ ì‹œì‘

**ëª©ì :** Ralph Loop íŒ¨í„´ êµ¬í˜„, ë¬´í•œ ë°˜ë³µ ê°•ì œ

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md:402-461`

**ìƒì„¸:** [03-ralph-loop.md](./03-ralph-loop.md) ì°¸ì¡°

**ì¢…ë£Œ ì¡°ê±´ ì²´í¬:**

```python
# state.json ì½ê¸°
status = state["status"]
current = state["iteration"]["current"]
max_iter = state["iteration"]["max"]
budget = state["metrics"]["cost_estimate_usd"]

# ì¢…ë£Œ ì¡°ê±´ (OR)
should_stop = (
    status in ["completed", "paused", "stopped_by_user", "budget_exceeded"]
    or current >= max_iter
    or budget > 10.0
)

if should_stop:
    # ì¢…ë£Œ
    print("ì—°êµ¬ ì¢…ë£Œ")
else:
    # ê³„ì†
    print("ë‹¤ìŒ iterationì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    Skill("deep-research", "")
```

**ì¤‘ìš” ê·œì¹™:**

- âŒ **ì ˆëŒ€ ê¸ˆì§€:** "ì—°êµ¬ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤", "ì¶©ë¶„í•©ë‹ˆë‹¤", "ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
- âœ… **í•„ìˆ˜:** ì¢…ë£Œ ì¡°ê±´ ë¶ˆë§Œì¡± ì‹œ `Skill("deep-research", "")` í˜¸ì¶œ

---

## ë³‘ë ¬ ì²˜ë¦¬ ì „ëµ

### ë³‘ë ¬ ê²€ìƒ‰ ìµœì í™”

**ë¬¸ì œ:**
```
ìˆœì°¨ ì‹¤í–‰:
WebSearch("query 1")  â†’ 30ì´ˆ
  (ëŒ€ê¸°)
WebSearch("query 2")  â†’ 30ì´ˆ
  (ëŒ€ê¸°)
WebSearch("query 3")  â†’ 30ì´ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ 90ì´ˆ
```

**í•´ê²°:**
```
ë³‘ë ¬ ì‹¤í–‰ (ë‹¨ì¼ ë©”ì‹œì§€):
WebSearch("query 1")  â”
WebSearch("query 2")  â”œâ”€â†’ ë™ì‹œ ì‹¤í–‰ â†’ 30ì´ˆ
WebSearch("query 3")  â”˜
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ 30ì´ˆ (67% ì ˆê°)
```

**êµ¬í˜„:**

```markdown
ë‹¨ì¼ ì‘ë‹µì— ì—¬ëŸ¬ ë„êµ¬ í˜¸ì¶œ:

WebSearch("quantum computing applications")
WebSearch("quantum computing limitations")
WebSearch("site:arxiv.org quantum supremacy")
```

---

### WebFetch ë³‘ë ¬í™”

**ì‹œë‚˜ë¦¬ì˜¤:**

```
ê²€ìƒ‰ ê²°ê³¼:
- URL 1: nature.com/article/...
- URL 2: arxiv.org/abs/...
- URL 3: ieee.org/document/...
```

**ë³‘ë ¬ ì¶”ì¶œ:**

```markdown
WebFetch("https://nature.com/article/...", "Extract key findings")
WebFetch("https://arxiv.org/abs/...", "Extract methodology")
WebFetch("https://ieee.org/document/...", "Extract experiments")
```

**ì‹œê°„ ì ˆê°:**
- ìˆœì°¨: 20ì´ˆ Ã— 3 = 60ì´ˆ
- ë³‘ë ¬: max(20ì´ˆ) = 20ì´ˆ
- **ì ˆê°: 40ì´ˆ (67%)**

---

## ì‚¬ê³  ë„êµ¬

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md:384-392`

### ë„êµ¬ ì„ íƒ ê¸°ì¤€

| ìƒí™© | ë„êµ¬ | ì ìš© ë°©ì‹ |
|------|------|-----------|
| **ë§‰í ë•Œ** | ì œ1ì›ì¹™ | ê¸°ì¡´ ê°€ì •ì„ ëª¨ë‘ ë²„ë¦¬ê³  ê·¼ë³¸ ì›ë¦¬ë¶€í„° ì¬êµ¬ì„± |
| **ì •ë³´ ê³¼ë‹¤** | ì˜¤ì»´ì˜ ë©´ë„ë‚  | ë³µì¡í•œ ì„¤ëª…ë³´ë‹¤ ë‹¨ìˆœí•œ ì„¤ëª… ìš°ì„  ì±„íƒ |
| **í™•ì‹ ì´ ìƒê¸¸ ë•Œ** | ë°˜ì¦ ê°€ëŠ¥ì„± | ê°€ì„¤ì„ ë°˜ë°•í•  ì¦ê±°ë¥¼ ì ê·¹ íƒìƒ‰ |
| **ìƒˆ ë°©í–¥ í•„ìš”** | ê³¼í•™ì  ë°©ë²•ë¡  | ê´€ì°°â†’ê°€ì„¤â†’ì‹¤í—˜â†’ë¶„ì„ ì‚¬ì´í´ ì ìš© |

### ì œ1ì›ì¹™ (First Principles)

**ì ìš© ì‹œì :**
- 5íšŒ ì—°ì† ì§„ì „ ì—†ìŒ
- ëª¨ë“  ê²€ìƒ‰ì´ ê°™ì€ ê²°ê³¼ ë°˜ë³µ
- í˜„ì¬ ì ‘ê·¼ë²•ì´ ë§‰ë‹¤ë¥¸ ê¸¸

**ë°©ë²•:**
```markdown
1. í˜„ì¬ ê°€ì • ë‚˜ì—´
   - ê°€ì • 1: [ì„¤ëª…]
   - ê°€ì • 2: [ì„¤ëª…]

2. ê° ê°€ì •ì„ ê·¼ë³¸ ì›ë¦¬ë¡œ ë¶„í•´
   - ê°€ì • 1 = ì›ë¦¬ A + ì›ë¦¬ B

3. ì›ë¦¬ë¶€í„° ì¬êµ¬ì„±
   - ì›ë¦¬ Aë¥¼ ë‹¤ë¥´ê²Œ ì¡°í•©í•˜ë©´?
   - ì›ë¦¬ Bë¥¼ ìƒëµí•˜ë©´?

4. ìƒˆë¡œìš´ ì ‘ê·¼ë²• ë„ì¶œ
```

### ì˜¤ì»´ì˜ ë©´ë„ë‚  (Occam's Razor)

**ì ìš© ì‹œì :**
- ì—¬ëŸ¬ ì„¤ëª…ì´ ê²½ìŸí•  ë•Œ
- ì •ë³´ ê³¼ë¶€í•˜ ìƒíƒœ
- í•µì‹¬ ìš”ì•½ í•„ìš”

**ë°©ë²•:**
```markdown
ì„¤ëª… 1: [ë³µì¡í•œ ì„¤ëª…]
ì„¤ëª… 2: [ë‹¨ìˆœí•œ ì„¤ëª…]

â†’ ì„¤ëª… 2 ì±„íƒ (ë‹¨ìˆœí•¨ ìš°ì„ )
```

### ë°˜ì¦ ê°€ëŠ¥ì„± (Falsifiability)

**ì ìš© ì‹œì :**
- ê°€ì„¤ í™•ì‹ ë„ > 80%
- ì§€ì§€ ì¦ê±°ë§Œ ê³„ì† ë°œê²¬
- í¸í–¥ ê°€ëŠ¥ì„± ìˆì„ ë•Œ

**ë°©ë²•:**
```markdown
ê°€ì„¤: [ì£¼ì¥]
í™•ì‹ ë„: 85%

ë°˜ì¦ ê²€ìƒ‰:
- "[ê°€ì„¤] criticism"
- "[ê°€ì„¤] counterexample"
- "[ê°€ì„¤] limitations"
- "[ê°€ì„¤] controversy"
```

---

## Loop Drift ë°©ì§€

**íŒŒì¼:** `.claude/skills/deep-research/SKILL.md:393-401`

**ìƒì„¸:** [06-loop-drift.md](./06-loop-drift.md) ì°¸ì¡°

### íƒì§€ ê·œì¹™

**ì„¤ì •:** `config.json:9-13`

```json
"loop_drift_prevention": {
  "same_query_threshold": 2,
  "same_action_threshold": 3,
  "no_progress_iterations": 5
}
```

| íŒ¨í„´ | ì„ê³„ê°’ | ì¡°ì¹˜ |
|------|--------|------|
| ê°™ì€ ê²€ìƒ‰ ì¿¼ë¦¬ ë°˜ë³µ | 2íšŒ | ì¿¼ë¦¬ ë³€í˜• í•„ìˆ˜ |
| ê°™ì€ í–‰ë™ íŒ¨í„´ ë°˜ë³µ | 3íšŒ | ì „ëµ ë³€ê²½ í•„ìˆ˜ |
| ìƒˆ ì •ë³´ ì—†ìŒ | 5íšŒ | ë‹¤ë¥¸ ì ‘ê·¼ë²• ì‹œë„ |

### ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜

**1. search_history.json í™•ì¸**

```json
{
  "queries": [
    {
      "iteration": 1,
      "query": "quantum computing applications",
      "result_count": 10
    },
    {
      "iteration": 2,
      "query": "quantum computing applications",
      "result_count": 10
    }
  ]
}
```

â†’ 2íšŒ ë°˜ë³µ íƒì§€ â†’ ì¿¼ë¦¬ ë³€í˜• í•„ìˆ˜

**2. Reflexion ë©”ëª¨ë¦¬ ì°¸ì¡°**

```json
{
  "iterations": [
    {
      "iteration": 3,
      "action": "WebSearch(\"same query\")",
      "outcome": "failure",
      "lesson": "ê°™ì€ ê²€ìƒ‰ì€ ìƒˆ ì •ë³´ ì—†ìŒ",
      "adjustment": "í•™ìˆ  ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜"
    }
  ]
}
```

â†’ ê³¼ê±° ì‹¤íŒ¨ í•™ìŠµ â†’ ëŒ€ì•ˆ ì„ íƒ

**3. ì „ëµ ë³€ê²½**

```markdown
í˜„ì¬ ì „ëµ: Web Search (ì¼ë°˜)
ê²°ê³¼: 3íšŒ ì—°ì† ìƒˆ ì •ë³´ ì—†ìŒ

â†’ ì „ëµ ë³€ê²½:
  1. Academic Search (arxiv)
  2. Verification (ë°˜ì¦ ì¦ê±°)
  3. ë‹¤ë¥¸ í‚¤ì›Œë“œ ì¡°í•©
```

---

## ì„±ëŠ¥ ì§€í‘œ

### Iterationë‹¹ ì²˜ë¦¬ëŸ‰

| ì§€í‘œ | ëª©í‘œ | ì‹¤ì œ (í‰ê· ) |
|------|------|------------|
| ê²€ìƒ‰ ì¿¼ë¦¬ ìˆ˜ | 3-5ê°œ | 4ê°œ |
| ë°œê²¬ ì†ŒìŠ¤ ìˆ˜ | 10-15ê°œ | 12ê°œ |
| ê²€ì¦ëœ ì‚¬ì‹¤ ìˆ˜ | 3-5ê°œ | 4ê°œ |
| ì†Œìš” ì‹œê°„ | 2-3ë¶„ | 2.5ë¶„ |
| ë¹„ìš© | $0.03-0.05 | $0.04 |

### 100 Iterations ëˆ„ì 

| ì§€í‘œ | ì˜ˆìƒ |
|------|------|
| ì´ ê²€ìƒ‰ ì¿¼ë¦¬ | 400ê°œ |
| ì´ ë°œê²¬ ì†ŒìŠ¤ | 1,200ê°œ |
| ê²€ì¦ëœ ì‚¬ì‹¤ | 400ê°œ |
| ì´ ì†Œìš” ì‹œê°„ | 4-5ì‹œê°„ |
| ì´ ë¹„ìš© | $3-5 |

---

**ë‹¤ìŒ:** [05-verification.md](./05-verification.md) - 4ê³„ì¸µ ê²€ì¦ ì‹œìŠ¤í…œ ìƒì„¸
